{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OppgaveDS.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/computas/ml-intro/blob/master/101-data-som-virkelighet/OppgaveDS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPJAeVM1qOir"
      },
      "source": [
        "# Problemstilling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIzkxYlDqTxL"
      },
      "source": [
        "Tenkt deg at datoen er 29. april 2020. Mange byer og stater i verden begynner å se de aller første tilfellene av coronaviruset, noen steder har pandemien kommet ganske langt allerede. New York State er en av statene der pandemien har kommet langt, og de er også gode til å samle inn data. Din oppgave er å lage en modell for å **predikere hvilke bydeler som er mest utsatt for å få mange dødsfall fra viruset**. Modellen skal andvendes i andre storbyer i verden i det de oppdager sine første koronatilfeller. Meningen er at man skal gå inn og teste mange, samt gjøre andre forebyggende tiltak i bydeler der man predikerer at antall dødsfall kommer til å bli høyt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kNKPZiOv2FZ"
      },
      "source": [
        "For å evaluere modellen bruker vi [leave-one-out cross validation](https://link.springer.com/referenceworkentry/10.1007%2F978-0-387-30164-8_469), og vi evaluerer med RMS. Det er skrevet en metode som gjør dette."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abfCWf_-AKZL"
      },
      "source": [
        "### Forklaring til dataene\n",
        "\n",
        "Alle dataene er oppdatert 28. april 2020.\n",
        "\n",
        "|Variabel | Forklaring\n",
        "|--------- | -------------\n",
        "|deaths | registrerte dødsfall\n",
        "|cumulative_positives | totalt antall som har testet positivt\n",
        "|cumulative_tests | totalt antall som er testet\n",
        "|medianFamily  | median inntekt for en familiy\n",
        "|density  | antall personer som bor per km2\n",
        "|population | befolkning\n",
        "|smoking   | prosentandel som røyker\n",
        "|infected  | andel av befolkingen som har blitt syke\n",
        "|county    | staten New York er delt inn i counties\n",
        "|arealand      | arealet til county"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9KMMzJKAKZN"
      },
      "source": [
        "### Datakilder\n",
        "* Antall døde i sentrum av New York per county\n",
        "https://www1.nyc.gov/site/doh/covid/covid-19-data-archive.page\n",
        "* Antall døde i hvert county, men flere i sentrum blir telt sammen, dermed ble det kombinert med forrige\n",
        "https://github.com/nytimes/covid-19-data (Data from The New York Times, based on reports from state and local health agencies.)\n",
        "* Data om antall testede\n",
        "https://data.ny.gov/\n",
        "* Andel som røyker\n",
        "https://health.data.ny.gov/Health/Community-Health-Indicator-Reports-CHIRS-Latest-Da/54ci-sdfi\n",
        "* Populasjon og areal av counties\n",
        "https://www.wolframalpha.com/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a07ivQwAKZP"
      },
      "source": [
        "# Oppgaven\n",
        "\n",
        "Vi har skrevet en notebook som tar deg gjennom å utforske dataene, samt lage en modell. \n",
        "Ha hele tiden oppgavens problemstilling i bakhode mens du jobber deg gjennom denne notebook\n",
        "\n",
        "1. Gjør utforskende dataanalyse. Det skal ikke være noe galt med dataene, vi har allerede gått igjennom følgende sjekkliste for å se at alt stemmer: https://docs.google.com/document/d/1km5mnhdYrAO3_2u0B06YSYPQLykuTQmujAuwjQjfAeA/edit?usp=gmail&ts=5e97143a. Det eneste er at vi er på grensen til å ha litt for lite data til å lage en god modell. En slik sjekkliste er veldig nyttig, men noen ganger ikke nok. Det er også viktig å tenke seg godt om når man utforsker dataene og tester ut modeller.\n",
        "Husk spesielt å:\n",
        "* Plotte distribusjonene til hver av variablene\n",
        "* Lag scatterplot for å se på korrelasjon mellom variablene\n",
        "\n",
        "2. Prøv å sett opp en enkel modell, test linear regresjon og random forest til å begynne med. \n",
        "For å evaluere modellen bruker vi leave-one-out cross validation, og vi evaluerer med [MSE](https://en.wikipedia.org/wiki/Mean_squared_error). Det er skrevet en metode som gjør dette. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Okoyept70PK"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "import sklearn\n",
        "from sklearn import preprocessing\n",
        "import sklearn.feature_selection\n",
        "from sklearn.model_selection import (train_test_split,\n",
        "                                     cross_val_score,\n",
        "                                     cross_val_predict,\n",
        "                                     cross_validate)\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor  "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GZazHAEAKZy",
        "cellView": "form"
      },
      "source": [
        "#@title Definer `corr_heatmap` funksjonen (du må kjøre denne cellen)\n",
        "def corr_heatmap(df, figsize=(10,10)):\n",
        "    _, axs = plt.subplots(figsize=figsize)\n",
        "    ax = sns.heatmap(df, vmin=-1, vmax=1, cmap=\"BrBG\", linewidths=0.5, annot=True, ax=axs)\n",
        "    ax.set_title('Correlation matrix')\n",
        "    return ax"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kznrzo4TAKZm",
        "cellView": "form"
      },
      "source": [
        "#@title Definer `makeHistogram` funksjonen (du må kjøre denne cellen)\n",
        "#Hjelpefunksjon for histogrammer\n",
        "def makeHistogram(data,variable,binwidth,upper_lim=None,lower_lim=None):\n",
        "    if upper_lim==None:\n",
        "        upper_lim=data[variable].max()\n",
        "    if lower_lim==None:\n",
        "        lower_lim=data[variable].min()\n",
        "    bins=np.arange(lower_lim, upper_lim + binwidth, binwidth)\n",
        "    plt.hist(data[variable],bins=bins,range=[data[variable].min(),upper_lim]) \n",
        "    plt.ylabel(\"frequency\")\n",
        "    plt.xlabel(variable)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxvS_5xPLW5i"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vT8OJifZAKZ5",
        "cellView": "form"
      },
      "source": [
        "#@title Definer `makeScatterPlot` funksjonen (du må kjøre denne cellen)\n",
        "def makeScatterPlot(data,para1,para2,logx=False,logy=False):\n",
        "    plt.plot(data[para1],data[para2],'*')\n",
        "    if logx:\n",
        "        plt.xscale(\"log\")\n",
        "    if logy:    \n",
        "        plt.yscale('log')\n",
        "    plt.xlabel(para1)\n",
        "    plt.ylabel(para2)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6pQnBzTNjKG"
      },
      "source": [
        "Last ned data fra git (bare hvis du kjører fra colab)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7LfXYPjNmlD"
      },
      "source": [
        "# Hent data\n",
        "!wget -c https://raw.githubusercontent.com/computas/ml-intro/master/101-data-som-virkelighet/newYorkData.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0H-xD7EvAKZX"
      },
      "source": [
        "# Importer dataene og få en første oversikt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKrQw9CVAKZY"
      },
      "source": [
        "data = pd.read_csv(\"newYorkData.csv\")\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYjUycqLAKZc"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HtDDpfRAKZh"
      },
      "source": [
        "data.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0zu1Dk5qKMZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWCJcwBDvArN"
      },
      "source": [
        "# Utforsk dataene"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhvGtvoRrEbo"
      },
      "source": [
        "Utforsk dataene:\n",
        "- Hvilke variable ser ut til å påvirke antall dødsfall?\n",
        "- Dersom dere skulle lage en modell, hvordan ville dere satt den opp?\n",
        "- Hvilke variable ville dere brukt? \n",
        "\n",
        "Dere har fått to hjelpefunksjoner for å lage histogrammer og scatterplot av dataene."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmDc0wwdWUGL"
      },
      "source": [
        "Dersom du er usikker på hva et histogram eller et scatterplot er kan det være nyttig å lese dette: \n",
        "\n",
        "Histogrammer: https://statistics.laerd.com/statistical-guides/understanding-histograms.php\n",
        "\n",
        "Scatterplot: https://chartio.com/learn/charts/what-is-a-scatter-plot/\n",
        "Eller du kan spørre en av medhjelperene\n",
        "\n",
        "Vi kommer også til å undersøke scatterplots og korrelasjoner. Er du litt usikker på disse begrepene, kan du lese følgende:\n",
        "https://www.westga.edu/academics/research/vrc/assets/docs/scatterplots_and_correlation_notes.pdf\n",
        "\n",
        "Hvis `r` er korrelasjonsverdien, vi kan klassifisere styrken av korrelasjonen via følgende tabell:\n",
        "\n",
        "Absolute Value of r | Strength of Relationship\n",
        "--- | ---\n",
        "r < 0.3 | None or very weak\n",
        "0.3 < r <0.5 | Weak\n",
        "0.5 < r < 0.7 | Moderate\n",
        "r > 0.7 | Strong\n",
        "\n",
        "Om du vil trene på korrelasjon og scatterplots, kan du ta noen runder med følgende spill:\n",
        "http://guessthecorrelation.com/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qN68hK6Vc-Xp"
      },
      "source": [
        "Vi begynner nmed å lage en correlation heat map for å få en oversikt over hvor det kan være korrelasjoner. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntC09tAJAKZ1"
      },
      "source": [
        "corr_heatmap(data.corr())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Unw8EMjAKZy"
      },
      "source": [
        "# Sjekk distribusjonen av variable og korrelasjonen mellom variablene\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vKRPaJSmFLN"
      },
      "source": [
        "Plot histogrammene for de variablene du mener er mest interessante"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rbeo7IH7qKdc"
      },
      "source": [
        "makeHistogram(data,\"cumulative_positives\",lower_lim=0,upper_lim=None,binwidth=1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEYf1q6qByq5"
      },
      "source": [
        "Plot dine egne histogrammer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQdfViDHB3LL"
      },
      "source": [
        "makeHistogram(data,....)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-gse-HfAKZ5"
      },
      "source": [
        "Vi ser det er en del sterke korrelasjoner. Lag scatterplot for de du mener er interessante, prøv også å bruke log skala. Spesielt ser det ut til at population er korrelert med dødsfall. For hvert scatterplot du lager, tenk igjennom hvorfor det ser ut som det gjør. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cegWzd71qKgb"
      },
      "source": [
        "makeScatterPlot(data,\"medianFamily\",\"deaths\",logx=False, logy=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upO8nTcQB7zV"
      },
      "source": [
        "Plot dine egne scatterplot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMhuyb2-B_6J"
      },
      "source": [
        "makeScatterPlot(data,...)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3Yo6bEOAKZ_"
      },
      "source": [
        "# Diskuter\n",
        "Det ser ut til at både `cumulative_tests`, `cumulative_ positives` er gode prediktorer. Men allikevel er det ikke sikkert at de bør brukes når man lager en modell. \n",
        "\n",
        "Gå tilbake og les problemstillingen en gang til, diskuter om det er variable vi ikke kan bruke. (hint: har vi tilgjengelig alle variabler når vi skal predikere?)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utNfOfvzAKaA"
      },
      "source": [
        "<details> \n",
        "  <summary> Trykk på pilen først etter at dere har diskutert </summary>\n",
        "  Modellen skal brukes i det de første tilfellene dukker opp i en by. På det tidspunktet vet man ikke noe om hvor mange som er smittet, hvor mange som er testet eller hvor mange som har testet positivt. Man ønsker å bruke modellen til å påvirke disse variablene, dermed kan de ikke være en del av modellen\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUsoLxRVAKaA"
      },
      "source": [
        "# Prøv dere frem med noen enkle modeller og diskuter. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sc1MI9dxAKaB"
      },
      "source": [
        "Basert på konklusjonen av diskusjonen i forrige oppgave fokuserer vi på `population`, `medianFamily`, `smoking` og `density`. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJRIrr8FAKaC"
      },
      "source": [
        "Vi tester en enkel random forest modell. Random forest er ikke avhenige av lineære sammenhenger. Vi har skrevet en enkel funksjon for dere som gjøre leave-one-out cross validering av modellen. Test modellen med forskjellig kombinasjon av uavhenige variable. Sjekk feature importance. Hvilke features ser ut til å være viktige:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJTlOLtyAKaD",
        "cellView": "form"
      },
      "source": [
        "#@title Definer `train_model` Funksjonen trener modellen og returnerer prediksjonene, rms, modellen og feature importance.\n",
        "def train_model(data, columns):\n",
        "    regressor = RandomForestRegressor(random_state=4, max_depth=3)\n",
        "\n",
        "    def predict(train, test):\n",
        "        test = test[columns]\n",
        "        X = train[columns]\n",
        "        y = train[\"deaths\"]\n",
        "        regressor.fit(X, y)\n",
        "        prediction = regressor.predict(test)\n",
        "        return prediction\n",
        "\n",
        "    predictions = []\n",
        "    result = data[columns]\n",
        "    result[\"deaths\"] = data[\"deaths\"]\n",
        "    for i in range(len(data)):\n",
        "        predicted = predict(data.drop([i]), data.iloc[[i]])\n",
        "        predictions.append(predicted[0])\n",
        "    result[\"predictions\"] = predictions\n",
        "    result[\"diff\"] = result[\"predictions\"] - result[\"deaths\"]\n",
        "    error = np.sqrt(mean_squared_error(result[\"deaths\"], result[\"predictions\"]))\n",
        "    model = regressor.fit(data[columns], data[\"deaths\"])\n",
        "    # Add shap importances, example: https://www.kaggle.com/wrosinski/shap-feature-importance-with-feature-engineering\n",
        "    importance = model.feature_importances_\n",
        "    return result, error, model, importance"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "1RSbM8agtLCf"
      },
      "source": [
        "#@title Definer `print_evaluation`. Funksjonen skriver ut RMS og feature importance\n",
        "def print_evaluation(rms:float,feature_importance:list, features:list):\n",
        "  print(f\"RMS: {rms}\")\n",
        "  print(\"Feature importance:\")\n",
        "  for items in list(zip(features,feature_importance)):\n",
        "    print(f\"{items[0]}: \\t {items[1]}\")\n",
        "  return"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABUWeQ9NC9Pj"
      },
      "source": [
        "Prøv og bruk et subset av uanvhenige variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLKrNqLKAKaI"
      },
      "source": [
        "# Define columns\n",
        "columns=[\"population\",\"density\",\"medianFamily\",\"smoking\"]\n",
        "\n",
        "# Train your model\n",
        "result,rms,model,importance = train_model(data,columns)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyNEBNnBAKaL"
      },
      "source": [
        "print_evaluation(rms,importance,columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWscuroKAKaU"
      },
      "source": [
        "<details>\n",
        " <summary> Trykk på pilen først etter at dere har prøvd dere frem litt </summary>\n",
        "Egentlig så ser det ut som om det er best å bruke kun en uavhenige variabel. Dette gir mening, siden det er kun det vi har nok data til. Det ser ut til at \"population\" er den viktigste variablen\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdKXiB25AKaU"
      },
      "source": [
        "# La oss ta en tenkepause og diskutere litt igjen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cz18TabwAKaV"
      },
      "source": [
        "Det ser ut til at den viktigste uavhenige variablen er `population`. \n",
        "\n",
        "Tenk igjennom hvorfor. \n",
        "\n",
        "- Hvilken verdi gir det egentlig for å ha en modell som predikerer antall dødsfall som funksjon av antall innbyggere?\n",
        "- Dersom det ikke var noen forskjell på bydelene, hva ville sammenhengen mellom population og deaths da vært? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfElkGw6AKaV"
      },
      "source": [
        "Som nevnt i oppgaven så tenker vi oss nå at en annen by skal andvende modellen, men vil modellen slik den er nå gi verdi for den nye byen? Kan vi teste det på noen måte? Diskuter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CODX4UUhAKaW"
      },
      "source": [
        "<details> \n",
        "  <summary> Trykk på pilen først etter at dere har diskutert </summary>\n",
        "    Det er ganske logisk at det er en sammenheng mellom antall folk i en bydel og hvor mange som dør av korona. Dersom alle bydelene har samme risiko, det vil si samme prosentandel som dør, så ville man sett en lineær sammenheng.\n",
        "    Altså ville man sett en sterk korrelasjon mellom population og deaths selv om alle bydelene var like utsatt. Dersom modellen skal være overførbar til en annen by, burde modellen fungere selv om man valgte å dele inn bydelene på en annen måte. Vi kan gjøre en test ved å slå sammen alle bydelene med mindre enn 70000 inbyggere til en ny bydel, og se hva den modellen predikerer.\n",
        "    </details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuBVBfdpAKaW"
      },
      "source": [
        "# Gjør en county sammenslåing (kommunesammenslåing :))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUFb5tSUEbxk"
      },
      "source": [
        "Vi trener modellen med kun population som uavhenige variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1NqP8LgAKaX"
      },
      "source": [
        "columns = [\"population\"]\n",
        "result,rms,model,importance = train_model(data,columns)\n",
        "print_evaluation(rms,importance,columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6by8m03ODYE9"
      },
      "source": [
        "Vi slår sammen alle counties som har mindre enn 70000 inbyggere til en ny county"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELkT5S5NAKaa"
      },
      "source": [
        "# Hent alle datapunkter med mindre enn 70000 innbyggere\n",
        "small = data[data[\"population\"]<70000]\n",
        "newCounty = pd.DataFrame()\n",
        "newCounty = newCounty.append(pd.Series(),ignore_index=True)\n",
        "\n",
        "# Beregn deaths, density og population for den nye datapunktet \n",
        "newCounty[\"deaths\"] = small[\"deaths\"].sum()\n",
        "newCounty[\"density\"] = small[\"population\"].sum()/small[\"arealand\"].sum()\n",
        "newCounty[\"population\"] = small[\"population\"].sum()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VbKWdCqAKad"
      },
      "source": [
        "newCounty"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vt9h8WrlAKag"
      },
      "source": [
        "# Hva sier modellen?\n",
        "prediction = model.predict(newCounty[columns])[0]\n",
        "real = newCounty['deaths'][0]\n",
        "print(f\"Modellen predikerer {prediction} dødsfall, men i virkeligheten har vi bare {real} dødsfall\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWzY6EogAKaj"
      },
      "source": [
        "Dette gikk jo veldig feil. I det nye county så predikerer vi altfor mange dødfall, men det reelle tallet var bare 50. Diskuter hva som skjedde her. Vil en modell som kun bruker density fungere bedre dersom vi slår sammen county. Hvorfor er det heller ikke ideelt å kun bruke density"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lbWnzMNAKak"
      },
      "source": [
        "<details> \n",
        "  <summary> Trykk på pilen først etter at dere har diskutert </summary>\n",
        "Egentlig så bør vi ikke ha med estimere antall dødfall. Fordi det vi egentlig er ute etter er å estimere hvilke bydeler som er mer utsatt for korona enn andre, det vil si hvilke bydeler som har en høyest dødsrate (antall døde per inbygger). Dermed bør vi heller lage en modell der vi predikerer dødsraten. For å evaluere modellen slik vi ble bedt om av oppdragsgiver, estimerer vi dødraten i hver bydel før vi ganger vi med population for å estimere antall som døde. Det ville vært det samme som å \n",
        "    </details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFzDrGEIAKal",
        "cellView": "form"
      },
      "source": [
        "#@title Definer funksjonen `makePredictionsUsingDeathRate` (du må kjøre denne cellen)\n",
        "def makePredictionsUsingDeathRate(data, columns, use_weight=False):\n",
        "    regressor = RandomForestRegressor(\n",
        "        n_estimators=200, random_state=42, bootstrap=True, max_depth=3\n",
        "    )\n",
        "    # regressor = DecisionTreeRegressor(max_depth=10)\n",
        "    def predict(train, test):\n",
        "        population = test.population.values[0]        \n",
        "        test = test[columns]\n",
        "        X = train[columns]\n",
        "        y = train[\"deathRate\"]\n",
        "        if use_weight:\n",
        "          train_population = train[\"population\"]\n",
        "          regressor.fit(X, y, sample_weight=train_population)\n",
        "        else:\n",
        "          regressor.fit(X, y)\n",
        "        prediction = regressor.predict(test)\n",
        "        return prediction[0] * population\n",
        "\n",
        "    predictions = []\n",
        "    result = data[columns]\n",
        "    result[\"deaths\"] = data[\"deaths\"]\n",
        "    for i in range(len(data)):\n",
        "        predicted = predict(data.drop([i]), data.iloc[[i]])\n",
        "        predictions.append(predicted)\n",
        "    result[\"predictions\"] = predictions\n",
        "    result[\"diff\"] = result[\"predictions\"] - result[\"deaths\"]\n",
        "    error = np.sqrt(mean_squared_error(result[\"deaths\"], result[\"predictions\"]))\n",
        "    model = regressor.fit(\n",
        "        data[columns], data[\"deathRate\"], sample_weight=data[\"population\"]\n",
        "    )\n",
        "    importance = model.feature_importances_\n",
        "    return result, error, model, importance"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n272u7DPAKao"
      },
      "source": [
        "data[\"deathRate\"] = data[\"deaths\"]/data[\"population\"]"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuT-lnTCAKas"
      },
      "source": [
        "columns=[\"density\"]"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RG0W38y4AKau"
      },
      "source": [
        "result,rms,model,importance = makePredictionsUsingDeathRate(data,columns)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0B2qfiJAKax"
      },
      "source": [
        "print_evaluation(rms,importance,columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUt-64eSAKa0"
      },
      "source": [
        "#Bruker modellen igjen for å predikere for det nye sammenslåtte county, og nå går det mye bedre\n",
        "predicted_death_rate = model.predict(newCounty[columns])[0]\n",
        "predicted_deaths = predicted_death_rate*newCounty[\"population\"][0]\n",
        "real_deaths = newCounty['deaths'][0]\n",
        "print(f\"Modellen predikerer {predicted_deaths} dødsfall, og i virkeligheten har vi {real_deaths} dødsfall\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lvx4B1AXISg0"
      },
      "source": [
        "Hva skjer med feature importance dersom vi bruker både både \"population\" og \"density\"?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-s75V9TAKa3"
      },
      "source": [
        "\n",
        "Vi ser at vi fikk en noe bedre modell bare ved å faktisk predikere riktig variabel. Men nå tenker vi på hver enkel bydel som et målepunkt. Er det riktig å gjøre? Har det noe å si om en bydel har flere inbyggere enn en annen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5739jgUVAKa3"
      },
      "source": [
        "<details> \n",
        "  <summary> Trykk på pilen først etter at dere har diskutert </summary>\n",
        "    I en bydel med stor befolkning har vi flere målepunkter, vi kan tenke på et dødsfall som et målepunkt. Det vil si at vi er mer sikre på dødsraten i en bydel med mange innbyggere. Dermed kan det være lurt å vekte dataene våre med population. Det kan gjøres ved å legge til parameter use_weight i funksjonen.\n",
        "    <code> makePredictionsUsingDeathRate(data,columns, use_weight=True) <code>\n",
        "    </details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXzSoPiJ0F4-"
      },
      "source": [
        "# Try to use the hint above\n"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMKweNd20GDa"
      },
      "source": [
        "# Se på koden her under om du ikke finner frem."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXzoJzvnIUM5",
        "cellView": "form"
      },
      "source": [
        "#@title Hint: Using density and population. Weighthing by population.\n",
        "columns=[\"density\",\"population\"]\n",
        "result,rms,model,importance = makePredictionsUsingDeathRate(data,columns, use_weight=True)\n",
        "print_evaluation(rms,importance,columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "kPZKUse4zoD-"
      },
      "source": [
        "#@title Hint: Using density. Weighthing by population.\n",
        "columns=[\"density\"]\n",
        "result,rms,model,importance = makePredictionsUsingDeathRate(data,columns, use_weight=True)\n",
        "print_evaluation(rms,importance,columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PxssxHWAKa4"
      },
      "source": [
        "# Hva har vi egentlig endt opp med?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATRzZpldAKa4"
      },
      "source": [
        "Vi endte opp med en modell som bruker kun density til å predikere death rate. Siden vi kun har en uavhenige variable kan vi plotte opp modellen.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6w8HTaF1AKa5"
      },
      "source": [
        "density = np.arange(data[\"density\"].min(),data[\"density\"].max())\n",
        "predicted = model.predict(density.reshape(-1,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpQBcnygAKa8"
      },
      "source": [
        "plt.plot(density,predicted)\n",
        "plt.plot(data[\"density\"],data[\"deathRate\"],'*')\n",
        "plt.xlabel(\"density\")\n",
        "plt.ylabel(\"death rate\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YELsjZMpAKa_"
      },
      "source": [
        "Vi ser at vi egentlig bare har gjort noe som ligner på en enkel kurvetilpassing. Konklusjonen av alt vi har gjort er at tettboddhet gjør en bydel utsastt for korona. Det ser også ut som om vi har en slags terskel, når man kommer over en tetthet på rundt 1000 personer per km^2 så begynner det å bli veldig farlig. Men alt dette kunne vi egentlig ha sett kun ved å plotte density mot deathRate.\n",
        "\n",
        "Ga alt vi gjorde med maskinlæring egentlig noe verdi? Diskuter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZSuPdWZAKa_"
      },
      "source": [
        "<details> \n",
        "  <summary> Trykk på pilen først etter at dere har diskutert </summary>\n",
        "  \n",
        "  I prosessen med å lage modellen så lært vi en del nyttig. Selv om konklusjonen vi kom frem til kunne man funnet ved kun å plotte deathRate mot density, så var veien dit lærerik. \n",
        "    \n",
        "- Det viktigste vi fant ut var at de andre variablene ikke hadde så mye å si. For eksempel hadde det lite å si hvor mange som røyket i bydelen, og hvor rik bydelen var. \n",
        "\n",
        "- Dersom man ikke hadde gått igjennom prosessen med å lage modellen, så hadde man fremdeles lurt på om disse variablene hadde noe å si. Men ved å lage modellen så ble vi mye sikrere på at tettboddhet er veldig viktig, mye viktigere enn de andre faktorene vi hadde informasjon om. \n",
        "\n",
        "- Vi hadde også så lite data at man bare kunne bruke en uavhenige variable for å lage en modell. Gjennom denne prosessen så fant vi ut hvilken variabel som var den viktigste, og vi fant ut at dersom man skal lage en bedre modell trenger man mere data, man må kanskje aggregere data fra flere andre byer.\n",
        "\n",
        "- Det er vår plikt å ikke være \"teknologi-blinde\" og fokusere bare på å bygge noe fordi vi kan, men vi må også validere at ting gir mening, og evt lære opp kunden vår i det de egentlig trenger. Kunden hadde bedt oss om å predikere dødsfall, og dette villedet oss litt på starten, men vi fant ut riktig tilnærming etter hvert.\n",
        "\n",
        "    </details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuhYq0GNAKbA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OgcTMO5v2mj"
      },
      "source": [
        "# Konklusjoner\n",
        "\n",
        " - Hva har vi lært?\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icH093bZv7PO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}